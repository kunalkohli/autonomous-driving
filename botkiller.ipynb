{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "unpickled_df = pd.read_pickle(\"dataset_new\")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 321 samples, validate on 107 samples\n",
      "Epoch 1/100\n",
      "321/321 [==============================] - 3s 10ms/step - loss: 1.1831 - categorical_accuracy: 0.3894 - val_loss: 1.0969 - val_categorical_accuracy: 0.4673\n",
      "Epoch 2/100\n",
      "321/321 [==============================] - 0s 473us/step - loss: 1.0819 - categorical_accuracy: 0.3427 - val_loss: 1.0956 - val_categorical_accuracy: 0.4953\n",
      "Epoch 3/100\n",
      "321/321 [==============================] - 0s 461us/step - loss: 1.0390 - categorical_accuracy: 0.4237 - val_loss: 1.0947 - val_categorical_accuracy: 0.4860\n",
      "Epoch 4/100\n",
      "321/321 [==============================] - 0s 467us/step - loss: 1.0176 - categorical_accuracy: 0.4174 - val_loss: 1.0914 - val_categorical_accuracy: 0.5047\n",
      "Epoch 5/100\n",
      "321/321 [==============================] - 0s 455us/step - loss: 0.9640 - categorical_accuracy: 0.4206 - val_loss: 1.0929 - val_categorical_accuracy: 0.4486\n",
      "Epoch 6/100\n",
      "321/321 [==============================] - 0s 473us/step - loss: 0.9445 - categorical_accuracy: 0.5078 - val_loss: 1.0902 - val_categorical_accuracy: 0.3832\n",
      "Epoch 7/100\n",
      "321/321 [==============================] - 0s 476us/step - loss: 0.9284 - categorical_accuracy: 0.5607 - val_loss: 1.0797 - val_categorical_accuracy: 0.4673\n",
      "Epoch 8/100\n",
      "321/321 [==============================] - 0s 457us/step - loss: 0.8725 - categorical_accuracy: 0.5639 - val_loss: 1.0329 - val_categorical_accuracy: 0.6636\n",
      "Epoch 9/100\n",
      "321/321 [==============================] - 0s 437us/step - loss: 0.8540 - categorical_accuracy: 0.6012 - val_loss: 1.0911 - val_categorical_accuracy: 0.2897\n",
      "Epoch 10/100\n",
      "321/321 [==============================] - 0s 417us/step - loss: 0.8791 - categorical_accuracy: 0.5981 - val_loss: 1.0626 - val_categorical_accuracy: 0.5327\n",
      "Epoch 11/100\n",
      "321/321 [==============================] - 0s 413us/step - loss: 0.8306 - categorical_accuracy: 0.6324 - val_loss: 0.9709 - val_categorical_accuracy: 0.7103\n",
      "Epoch 12/100\n",
      "321/321 [==============================] - 0s 415us/step - loss: 0.7922 - categorical_accuracy: 0.6417 - val_loss: 0.9930 - val_categorical_accuracy: 0.7196\n",
      "Epoch 13/100\n",
      "321/321 [==============================] - 0s 414us/step - loss: 0.7581 - categorical_accuracy: 0.6885 - val_loss: 0.8658 - val_categorical_accuracy: 0.7664\n",
      "Epoch 14/100\n",
      "321/321 [==============================] - 0s 422us/step - loss: 0.7689 - categorical_accuracy: 0.7040 - val_loss: 0.9179 - val_categorical_accuracy: 0.7664\n",
      "Epoch 15/100\n",
      "321/321 [==============================] - 0s 411us/step - loss: 0.6730 - categorical_accuracy: 0.7414 - val_loss: 0.8512 - val_categorical_accuracy: 0.8131\n",
      "Epoch 16/100\n",
      "321/321 [==============================] - 0s 414us/step - loss: 0.6594 - categorical_accuracy: 0.7321 - val_loss: 0.8560 - val_categorical_accuracy: 0.8131\n",
      "Epoch 17/100\n",
      "321/321 [==============================] - 0s 415us/step - loss: 0.6116 - categorical_accuracy: 0.7757 - val_loss: 0.8847 - val_categorical_accuracy: 0.7570\n",
      "Epoch 18/100\n",
      "321/321 [==============================] - 0s 414us/step - loss: 0.5805 - categorical_accuracy: 0.7508 - val_loss: 0.7992 - val_categorical_accuracy: 0.8131\n",
      "Epoch 19/100\n",
      "321/321 [==============================] - 0s 406us/step - loss: 0.5502 - categorical_accuracy: 0.7975 - val_loss: 0.7772 - val_categorical_accuracy: 0.8318\n",
      "Epoch 20/100\n",
      "321/321 [==============================] - 0s 414us/step - loss: 0.5244 - categorical_accuracy: 0.8193 - val_loss: 0.7696 - val_categorical_accuracy: 0.8505\n",
      "Epoch 21/100\n",
      "321/321 [==============================] - 0s 412us/step - loss: 0.5144 - categorical_accuracy: 0.8069 - val_loss: 0.7616 - val_categorical_accuracy: 0.8505\n",
      "Epoch 22/100\n",
      "321/321 [==============================] - 0s 413us/step - loss: 0.5291 - categorical_accuracy: 0.7913 - val_loss: 0.7076 - val_categorical_accuracy: 0.8318\n",
      "Epoch 23/100\n",
      "321/321 [==============================] - 0s 418us/step - loss: 0.5057 - categorical_accuracy: 0.8255 - val_loss: 0.8543 - val_categorical_accuracy: 0.7570\n",
      "Epoch 24/100\n",
      "321/321 [==============================] - 0s 428us/step - loss: 0.4948 - categorical_accuracy: 0.8069 - val_loss: 0.8562 - val_categorical_accuracy: 0.7477\n",
      "Epoch 25/100\n",
      "321/321 [==============================] - 0s 435us/step - loss: 0.4612 - categorical_accuracy: 0.8567 - val_loss: 0.6619 - val_categorical_accuracy: 0.8224\n",
      "Epoch 26/100\n",
      "321/321 [==============================] - 0s 451us/step - loss: 0.4082 - categorical_accuracy: 0.8505 - val_loss: 0.9164 - val_categorical_accuracy: 0.5701\n",
      "Epoch 27/100\n",
      "321/321 [==============================] - 0s 434us/step - loss: 0.4431 - categorical_accuracy: 0.8349 - val_loss: 0.5924 - val_categorical_accuracy: 0.8037\n",
      "Epoch 28/100\n",
      "321/321 [==============================] - 0s 436us/step - loss: 0.4583 - categorical_accuracy: 0.8162 - val_loss: 0.8216 - val_categorical_accuracy: 0.7944\n",
      "Epoch 29/100\n",
      "321/321 [==============================] - 0s 453us/step - loss: 0.4138 - categorical_accuracy: 0.8505 - val_loss: 0.6752 - val_categorical_accuracy: 0.8224\n",
      "Epoch 30/100\n",
      "321/321 [==============================] - 0s 446us/step - loss: 0.3596 - categorical_accuracy: 0.8629 - val_loss: 0.6229 - val_categorical_accuracy: 0.8598\n",
      "Epoch 31/100\n",
      "321/321 [==============================] - 0s 421us/step - loss: 0.3617 - categorical_accuracy: 0.8598 - val_loss: 0.6200 - val_categorical_accuracy: 0.7290\n",
      "Epoch 32/100\n",
      "321/321 [==============================] - 0s 422us/step - loss: 0.4090 - categorical_accuracy: 0.8598 - val_loss: 0.5696 - val_categorical_accuracy: 0.8411\n",
      "Epoch 33/100\n",
      "321/321 [==============================] - 0s 436us/step - loss: 0.3546 - categorical_accuracy: 0.8567 - val_loss: 0.7755 - val_categorical_accuracy: 0.7664\n",
      "Epoch 34/100\n",
      "321/321 [==============================] - 0s 437us/step - loss: 0.3287 - categorical_accuracy: 0.8910 - val_loss: 0.5539 - val_categorical_accuracy: 0.8692\n",
      "Epoch 35/100\n",
      "321/321 [==============================] - 0s 424us/step - loss: 0.3502 - categorical_accuracy: 0.8692 - val_loss: 0.6095 - val_categorical_accuracy: 0.8692\n",
      "Epoch 36/100\n",
      "321/321 [==============================] - 0s 468us/step - loss: 0.3588 - categorical_accuracy: 0.8816 - val_loss: 0.7068 - val_categorical_accuracy: 0.8505\n",
      "Epoch 37/100\n",
      "321/321 [==============================] - 0s 430us/step - loss: 0.3115 - categorical_accuracy: 0.8816 - val_loss: 0.7660 - val_categorical_accuracy: 0.8037\n",
      "Epoch 38/100\n",
      "321/321 [==============================] - 0s 416us/step - loss: 0.3579 - categorical_accuracy: 0.8629 - val_loss: 0.5792 - val_categorical_accuracy: 0.8505\n",
      "Epoch 39/100\n",
      "321/321 [==============================] - 0s 441us/step - loss: 0.3625 - categorical_accuracy: 0.8567 - val_loss: 0.6136 - val_categorical_accuracy: 0.8879\n",
      "Epoch 40/100\n",
      "321/321 [==============================] - 0s 435us/step - loss: 0.3402 - categorical_accuracy: 0.8629 - val_loss: 0.7408 - val_categorical_accuracy: 0.8318\n",
      "Epoch 41/100\n",
      "321/321 [==============================] - 0s 446us/step - loss: 0.3196 - categorical_accuracy: 0.8598 - val_loss: 0.6505 - val_categorical_accuracy: 0.8692\n",
      "Epoch 42/100\n",
      "321/321 [==============================] - 0s 473us/step - loss: 0.2919 - categorical_accuracy: 0.8941 - val_loss: 0.6869 - val_categorical_accuracy: 0.8131\n",
      "Epoch 43/100\n",
      "321/321 [==============================] - 0s 442us/step - loss: 0.3052 - categorical_accuracy: 0.8816 - val_loss: 0.6231 - val_categorical_accuracy: 0.8692\n",
      "Epoch 44/100\n",
      "321/321 [==============================] - 0s 416us/step - loss: 0.3070 - categorical_accuracy: 0.8879 - val_loss: 0.8851 - val_categorical_accuracy: 0.6636\n",
      "Epoch 45/100\n",
      "321/321 [==============================] - 0s 413us/step - loss: 0.3355 - categorical_accuracy: 0.8692 - val_loss: 0.6918 - val_categorical_accuracy: 0.8505\n",
      "Epoch 46/100\n",
      "321/321 [==============================] - 0s 414us/step - loss: 0.2997 - categorical_accuracy: 0.8816 - val_loss: 0.5931 - val_categorical_accuracy: 0.8692\n",
      "Epoch 47/100\n",
      "321/321 [==============================] - 0s 411us/step - loss: 0.2631 - categorical_accuracy: 0.8847 - val_loss: 0.6473 - val_categorical_accuracy: 0.8505\n",
      "Epoch 48/100\n",
      "321/321 [==============================] - 0s 414us/step - loss: 0.2824 - categorical_accuracy: 0.8972 - val_loss: 0.6141 - val_categorical_accuracy: 0.8598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "321/321 [==============================] - 0s 415us/step - loss: 0.3063 - categorical_accuracy: 0.8785 - val_loss: 0.7254 - val_categorical_accuracy: 0.8224\n",
      "Epoch 50/100\n",
      "321/321 [==============================] - 0s 408us/step - loss: 0.2896 - categorical_accuracy: 0.8910 - val_loss: 0.6039 - val_categorical_accuracy: 0.8318\n",
      "Epoch 51/100\n",
      "321/321 [==============================] - 0s 411us/step - loss: 0.2804 - categorical_accuracy: 0.9034 - val_loss: 0.5000 - val_categorical_accuracy: 0.8879\n",
      "Epoch 52/100\n",
      "321/321 [==============================] - 0s 413us/step - loss: 0.3488 - categorical_accuracy: 0.8567 - val_loss: 0.5127 - val_categorical_accuracy: 0.8785\n",
      "Epoch 53/100\n",
      "321/321 [==============================] - 0s 409us/step - loss: 0.2891 - categorical_accuracy: 0.8847 - val_loss: 0.5900 - val_categorical_accuracy: 0.8692\n",
      "Epoch 54/100\n",
      "321/321 [==============================] - 0s 411us/step - loss: 0.2288 - categorical_accuracy: 0.9190 - val_loss: 0.7165 - val_categorical_accuracy: 0.8318\n",
      "Epoch 55/100\n",
      "321/321 [==============================] - 0s 411us/step - loss: 0.2491 - categorical_accuracy: 0.8972 - val_loss: 0.5346 - val_categorical_accuracy: 0.8505\n",
      "Epoch 56/100\n",
      "321/321 [==============================] - 0s 417us/step - loss: 0.2150 - categorical_accuracy: 0.9283 - val_loss: 0.5275 - val_categorical_accuracy: 0.9065\n",
      "Epoch 57/100\n",
      "321/321 [==============================] - 0s 409us/step - loss: 0.2318 - categorical_accuracy: 0.9128 - val_loss: 0.5173 - val_categorical_accuracy: 0.8692\n",
      "Epoch 58/100\n",
      "321/321 [==============================] - 0s 411us/step - loss: 0.2314 - categorical_accuracy: 0.9034 - val_loss: 0.5096 - val_categorical_accuracy: 0.8879\n",
      "Epoch 59/100\n",
      "321/321 [==============================] - 0s 410us/step - loss: 0.2226 - categorical_accuracy: 0.9252 - val_loss: 0.5083 - val_categorical_accuracy: 0.8785\n",
      "Epoch 60/100\n",
      "321/321 [==============================] - 0s 408us/step - loss: 0.2564 - categorical_accuracy: 0.8910 - val_loss: 0.5235 - val_categorical_accuracy: 0.8785\n",
      "Epoch 61/100\n",
      "321/321 [==============================] - 0s 410us/step - loss: 0.2188 - categorical_accuracy: 0.9283 - val_loss: 0.5182 - val_categorical_accuracy: 0.8692\n",
      "Epoch 62/100\n",
      "321/321 [==============================] - 0s 411us/step - loss: 0.2337 - categorical_accuracy: 0.9159 - val_loss: 0.5019 - val_categorical_accuracy: 0.8692\n",
      "Epoch 63/100\n",
      "321/321 [==============================] - 0s 410us/step - loss: 0.2420 - categorical_accuracy: 0.9190 - val_loss: 0.4986 - val_categorical_accuracy: 0.9065\n",
      "Epoch 64/100\n",
      "321/321 [==============================] - 0s 414us/step - loss: 0.1886 - categorical_accuracy: 0.9190 - val_loss: 0.5217 - val_categorical_accuracy: 0.8692\n",
      "Epoch 65/100\n",
      "321/321 [==============================] - 0s 415us/step - loss: 0.2123 - categorical_accuracy: 0.9097 - val_loss: 0.4688 - val_categorical_accuracy: 0.9065\n",
      "Epoch 66/100\n",
      "321/321 [==============================] - 0s 416us/step - loss: 0.2250 - categorical_accuracy: 0.9190 - val_loss: 0.5123 - val_categorical_accuracy: 0.8785\n",
      "Epoch 67/100\n",
      "321/321 [==============================] - 0s 413us/step - loss: 0.2247 - categorical_accuracy: 0.9065 - val_loss: 0.4852 - val_categorical_accuracy: 0.9065\n",
      "Epoch 68/100\n",
      "321/321 [==============================] - 0s 417us/step - loss: 0.1870 - categorical_accuracy: 0.9252 - val_loss: 0.5222 - val_categorical_accuracy: 0.8598\n",
      "Epoch 69/100\n",
      "321/321 [==============================] - 0s 412us/step - loss: 0.1533 - categorical_accuracy: 0.9439 - val_loss: 0.4682 - val_categorical_accuracy: 0.8785\n",
      "Epoch 70/100\n",
      "321/321 [==============================] - 0s 408us/step - loss: 0.1861 - categorical_accuracy: 0.9128 - val_loss: 0.4981 - val_categorical_accuracy: 0.8972\n",
      "Epoch 71/100\n",
      "321/321 [==============================] - 0s 413us/step - loss: 0.2096 - categorical_accuracy: 0.9252 - val_loss: 0.5250 - val_categorical_accuracy: 0.8972\n",
      "Epoch 72/100\n",
      "321/321 [==============================] - 0s 410us/step - loss: 0.2111 - categorical_accuracy: 0.9221 - val_loss: 0.5076 - val_categorical_accuracy: 0.8879\n",
      "Epoch 73/100\n",
      "321/321 [==============================] - 0s 413us/step - loss: 0.2214 - categorical_accuracy: 0.9283 - val_loss: 0.5473 - val_categorical_accuracy: 0.8972\n",
      "Epoch 74/100\n",
      "321/321 [==============================] - 0s 413us/step - loss: 0.2145 - categorical_accuracy: 0.9097 - val_loss: 0.5471 - val_categorical_accuracy: 0.8692\n",
      "Epoch 75/100\n",
      "321/321 [==============================] - 0s 415us/step - loss: 0.2130 - categorical_accuracy: 0.9034 - val_loss: 0.4810 - val_categorical_accuracy: 0.9065\n",
      "Epoch 76/100\n",
      "321/321 [==============================] - 0s 417us/step - loss: 0.1687 - categorical_accuracy: 0.9315 - val_loss: 0.4764 - val_categorical_accuracy: 0.8692\n",
      "Epoch 77/100\n",
      "321/321 [==============================] - 0s 409us/step - loss: 0.1544 - categorical_accuracy: 0.9408 - val_loss: 0.4429 - val_categorical_accuracy: 0.8598\n",
      "Epoch 78/100\n",
      "321/321 [==============================] - 0s 411us/step - loss: 0.2143 - categorical_accuracy: 0.9097 - val_loss: 0.5089 - val_categorical_accuracy: 0.9065\n",
      "Epoch 79/100\n",
      "321/321 [==============================] - 0s 413us/step - loss: 0.1360 - categorical_accuracy: 0.9564 - val_loss: 0.4527 - val_categorical_accuracy: 0.9159\n",
      "Epoch 80/100\n",
      "321/321 [==============================] - 0s 411us/step - loss: 0.1408 - categorical_accuracy: 0.9439 - val_loss: 0.4404 - val_categorical_accuracy: 0.9065\n",
      "Epoch 81/100\n",
      "321/321 [==============================] - 0s 408us/step - loss: 0.1828 - categorical_accuracy: 0.9346 - val_loss: 0.4944 - val_categorical_accuracy: 0.9065\n",
      "Epoch 82/100\n",
      "321/321 [==============================] - 0s 411us/step - loss: 0.1542 - categorical_accuracy: 0.9408 - val_loss: 0.4904 - val_categorical_accuracy: 0.9065\n",
      "Epoch 83/100\n",
      "321/321 [==============================] - 0s 422us/step - loss: 0.1883 - categorical_accuracy: 0.9315 - val_loss: 0.4449 - val_categorical_accuracy: 0.9252\n",
      "Epoch 84/100\n",
      "321/321 [==============================] - 0s 411us/step - loss: 0.1744 - categorical_accuracy: 0.9439 - val_loss: 0.4419 - val_categorical_accuracy: 0.9159\n",
      "Epoch 85/100\n",
      "321/321 [==============================] - 0s 409us/step - loss: 0.1142 - categorical_accuracy: 0.9533 - val_loss: 0.4552 - val_categorical_accuracy: 0.9065\n",
      "Epoch 86/100\n",
      "321/321 [==============================] - 0s 415us/step - loss: 0.1768 - categorical_accuracy: 0.9346 - val_loss: 0.5682 - val_categorical_accuracy: 0.8879\n",
      "Epoch 87/100\n",
      "321/321 [==============================] - 0s 411us/step - loss: 0.2055 - categorical_accuracy: 0.9252 - val_loss: 0.4078 - val_categorical_accuracy: 0.8879\n",
      "Epoch 88/100\n",
      "321/321 [==============================] - 0s 412us/step - loss: 0.1756 - categorical_accuracy: 0.9190 - val_loss: 0.4378 - val_categorical_accuracy: 0.8785\n",
      "Epoch 89/100\n",
      "321/321 [==============================] - 0s 412us/step - loss: 0.1678 - categorical_accuracy: 0.9408 - val_loss: 0.4489 - val_categorical_accuracy: 0.9065\n",
      "Epoch 90/100\n",
      "321/321 [==============================] - 0s 410us/step - loss: 0.1648 - categorical_accuracy: 0.9502 - val_loss: 0.4369 - val_categorical_accuracy: 0.9065\n",
      "Epoch 91/100\n",
      "321/321 [==============================] - 0s 412us/step - loss: 0.1811 - categorical_accuracy: 0.9159 - val_loss: 0.4553 - val_categorical_accuracy: 0.8785\n",
      "Epoch 92/100\n",
      "321/321 [==============================] - 0s 419us/step - loss: 0.2027 - categorical_accuracy: 0.9221 - val_loss: 0.4100 - val_categorical_accuracy: 0.9065\n",
      "Epoch 93/100\n",
      "321/321 [==============================] - 0s 406us/step - loss: 0.1762 - categorical_accuracy: 0.9346 - val_loss: 0.4710 - val_categorical_accuracy: 0.9065\n",
      "Epoch 94/100\n",
      "321/321 [==============================] - 0s 416us/step - loss: 0.1574 - categorical_accuracy: 0.9439 - val_loss: 0.4543 - val_categorical_accuracy: 0.8972\n",
      "Epoch 95/100\n",
      "321/321 [==============================] - 0s 417us/step - loss: 0.1914 - categorical_accuracy: 0.9159 - val_loss: 0.4255 - val_categorical_accuracy: 0.9065\n",
      "Epoch 96/100\n",
      "321/321 [==============================] - 0s 410us/step - loss: 0.1062 - categorical_accuracy: 0.9564 - val_loss: 0.4346 - val_categorical_accuracy: 0.8879\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 0s 412us/step - loss: 0.1338 - categorical_accuracy: 0.9377 - val_loss: 0.4036 - val_categorical_accuracy: 0.9159\n",
      "Epoch 98/100\n",
      "321/321 [==============================] - 0s 422us/step - loss: 0.1369 - categorical_accuracy: 0.9564 - val_loss: 0.4277 - val_categorical_accuracy: 0.9065\n",
      "Epoch 99/100\n",
      "321/321 [==============================] - 0s 430us/step - loss: 0.2164 - categorical_accuracy: 0.9252 - val_loss: 0.4699 - val_categorical_accuracy: 0.8879\n",
      "Epoch 100/100\n",
      "321/321 [==============================] - 0s 443us/step - loss: 0.1563 - categorical_accuracy: 0.9408 - val_loss: 0.4016 - val_categorical_accuracy: 0.9065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bad70bfd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = unpickled_df[1]\n",
    "features = unpickled_df[0]\n",
    "batch_size = 32\n",
    "# split to train,test set \n",
    "# \n",
    "features_train, features_valid, prediction_train, prediction_valid = train_test_split(features, prediction, test_size=0.25, shuffle= True)\n",
    "features_train = features_train/255.\n",
    "features_valid = features_valid/255.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "from keras.layers import BatchNormalization, Conv1D, LSTM, Dense, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "#create model\n",
    "\n",
    "size = 128\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(4, kernel_size=(3, 3), padding='same', activation='relu',\n",
    "                input_shape=(size, size, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(4, kernel_size=(3, 3), padding='same', activation='relu',\n",
    "                input_shape=(size, size, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(4, kernel_size=(3, 3), padding='same', activation='relu',\n",
    "                input_shape=(size, size, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(2, kernel_size=(3, 3),  activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# model.add(Conv2D(8, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#train the model\n",
    "model.fit(features_train, prediction_train, validation_data=(features_valid, prediction_valid), epochs=100\n",
    "                      ,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
